{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Binary classification using the Titanic dataset\n\nOne of the classic public datasets used to demonstrate binary classification is the Titanic dataset, which lists the passengers aboard the RMS Titanic when it sank on April 15, 1912. The dataset includes the name of each passenger as well as other information such as the fare class, the fare price, the person's age and gender, and whether that person survived the sinking of the ship. In this example, we will build a binary-classification model that predicts whether a passenger will survive. We will build the model two ways — first as a logistic-regression model, and then as a Support Vector Machine (SVM) model — and compare the results.\n\n![](Images/titanic.png)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Load and prepare the dataset\n\nThe first step is to load the dataset and prepare it for training a machine-learning model. One of the reasons the Titanic dataset is popular is that it provides ample opportunity for data scientists to practice their data-cleaning skills."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Load the dataset\nimport pandas as pd\n\ndf = pd.read_csv('Data/titanic.csv')\ndf.head(10)",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Moran, Mr. James</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330877</td>\n      <td>8.4583</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n      <td>McCarthy, Mr. Timothy J</td>\n      <td>male</td>\n      <td>54.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>17463</td>\n      <td>51.8625</td>\n      <td>E46</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Palsson, Master. Gosta Leonard</td>\n      <td>male</td>\n      <td>2.0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>349909</td>\n      <td>21.0750</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n      <td>female</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>347742</td>\n      <td>11.1333</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>1</td>\n      <td>2</td>\n      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n      <td>female</td>\n      <td>14.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>237736</td>\n      <td>30.0708</td>\n      <td>NaN</td>\n      <td>C</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n5            6         0       3   \n6            7         0       1   \n7            8         0       3   \n8            9         1       3   \n9           10         1       2   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n5                                   Moran, Mr. James    male   NaN      0   \n6                            McCarthy, Mr. Timothy J    male  54.0      0   \n7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  \n5      0            330877   8.4583   NaN        Q  \n6      0             17463  51.8625   E46        S  \n7      1            349909  21.0750   NaN        S  \n8      2            347742  11.1333   NaN        S  \n9      0            237736  30.0708   NaN        C  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.info()",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\nPassengerId    891 non-null int64\nSurvived       891 non-null int64\nPclass         891 non-null int64\nName           891 non-null object\nSex            891 non-null object\nAge            714 non-null float64\nSibSp          891 non-null int64\nParch          891 non-null int64\nTicket         891 non-null object\nFare           891 non-null float64\nCabin          204 non-null object\nEmbarked       889 non-null object\ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.6+ KB\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We'll drop columns such as \"PassengerId\" and \"Name\" that have no bearing on the outcome. We will also drop the \"Fare\" column because there is colinearity between that column and the \"Pclass\" column. Finally, we will one-hot-encode the \"Sex\" and \"Pclass\" columns, and remove rows containing missing values."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin', 'Embarked', 'Fare'], axis=1, inplace=True)\ndf = pd.get_dummies(df, columns=['Sex', 'Pclass'])\ndf.dropna(inplace=True)\ndf.head()",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Sex_female</th>\n      <th>Sex_male</th>\n      <th>Pclass_1</th>\n      <th>Pclass_2</th>\n      <th>Pclass_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "   Survived   Age  SibSp  Parch  Sex_female  Sex_male  Pclass_1  Pclass_2  \\\n0         0  22.0      1      0           0         1         0         0   \n1         1  38.0      1      0           1         0         1         0   \n2         1  26.0      0      0           1         0         0         0   \n3         1  35.0      1      0           1         0         1         0   \n4         0  35.0      0      0           0         1         0         0   \n\n   Pclass_3  \n0         1  \n1         0  \n2         1  \n3         0  \n4         1  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.info()",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 714 entries, 0 to 890\nData columns (total 9 columns):\nSurvived      714 non-null int64\nAge           714 non-null float64\nSibSp         714 non-null int64\nParch         714 non-null int64\nSex_female    714 non-null uint8\nSex_male      714 non-null uint8\nPclass_1      714 non-null uint8\nPclass_2      714 non-null uint8\nPclass_3      714 non-null uint8\ndtypes: float64(1), int64(3), uint8(5)\nmemory usage: 31.4 KB\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now let's see which input variables have the mosty influence on the outcome."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.corr()[\"Survived\"].sort_values(ascending=False)",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "Survived      1.000000\nSex_female    0.538826\nPclass_1      0.301831\nParch         0.093317\nPclass_2      0.084753\nSibSp        -0.017358\nAge          -0.077221\nPclass_3     -0.337587\nSex_male     -0.538826\nName: Survived, dtype: float64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The number of parents accompanying the passenger (\"Parch\") and the number of siblings (\"SibSp\") have little effect on the outcome, so we'll remove those columns."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.drop(['Parch', 'SibSp'], axis=1, inplace=True)",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The final step is to split the data into two datasets: one for training and one for testing."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\n\nx = df.drop('Survived', axis=1)\ny = df['Survived']\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1234)",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Build and train a logistic-regression model\n\nOur first classifier will use logistic regression. One of the advantages of logistic regression is that it will not only make predictions, it will give you probabilities as well."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression()\nmodel.fit(x, y)",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n",
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='warn',\n          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n          tol=0.0001, verbose=0, warm_start=False)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Get the overall accuracy of the model\nmodel.score(x_test, y_test)",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "0.7762237762237763"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Show the confusion matrix\nfrom sklearn.metrics import confusion_matrix\n\nconfusion_matrix(y_test, model.predict(x_test))",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "array([[69, 16],\n       [16, 42]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import classification_report\n\npredictions = model.predict(x_test)\nprint(classification_report(y_test, predictions))",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.81      0.81      0.81        85\n           1       0.72      0.72      0.72        58\n\n   micro avg       0.78      0.78      0.78       143\n   macro avg       0.77      0.77      0.77       143\nweighted avg       0.78      0.78      0.78       143\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now let's the use the model to predict whether a 30-year-old female traveling in first class will survive the voyage."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "input = [30, 1, 0, 1, 0, 0]\nmodel.predict([input])",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "array([1])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "More to the point, what is the probability that a 30-year-old female traveling in first class will survive?"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "probability = model.predict_proba([input])[0][1]\nprint('Probability of survival: {:.1%}'.format(probability))",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Probability of survival: 92.7%\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Build and train an SVM model\n\nSupport-vector classifiers (classifiiers that use Support Vector Machines, or SVMs) frequently do better at fitting the data than classifiers that rely on logistic regression. Let's try a support-vector classifier on the same dataset and see if it fares better."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.svm import SVC\n\nmodel = SVC()\nmodel.fit(x, y)",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\n",
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n  shrinking=True, tol=0.001, verbose=False)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Get the overall accuracy of the model\nmodel.score(x_test, y_test)",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "0.8181818181818182"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Show the confusion matrix\nconfusion_matrix(y_test, model.predict(x_test))",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "array([[71, 14],\n       [12, 46]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "predictions = model.predict(x_test)\nprint(classification_report(y_test, predictions))",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": "              precision    recall  f1-score   support\n\n           0       0.86      0.84      0.85        85\n           1       0.77      0.79      0.78        58\n\n   micro avg       0.82      0.82      0.82       143\n   macro avg       0.81      0.81      0.81       143\nweighted avg       0.82      0.82      0.82       143\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now let's the use the model to predict whether a 30-year-old female traveling in first class will survive the voyage."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "model.predict([[30, 1, 0, 1, 0, 0]])",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "array([1])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "How about a 30-year-old male traveling in first class?"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "model.predict([[30, 0, 1, 1, 0, 0]])",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": "array([0])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Unfortunately, we can't get the probability that a passenger will survive because Support Vector Machines don't compute probabilities."
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}