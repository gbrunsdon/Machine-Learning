{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Sentiment analysis using binary classification\n\nOne of the common uses for binary classification in machine learning is analyzing text for sentiment â€” specifically, assigning a text string a score from 0 to 1, where 0 represents negative sentiment and 1 represents positive sentiment. A restaurant review such as \"Best meal I've ever had and awesome service, too!\" might score 0.9 or higher, while a statement such as \"Long lines and poor customer service\" would score closer to 0. Marketing departments sometimes use sentiment-anlysis models to monitor social-media services for feedback so they can respond quickly if, for example, comments regarding their company suddenly turn negative.\n\nTo train a sentiment-analysis model, you need a dataset containing text strings labeled with 0s (for negative sentiment) and 1s (for positive sentiment). Several such datasets are available in the public domain. We will use one containing 50,000 movie reviews, each labeled with a 0 or 1. Once the model is trained, scoring a text string for sentiment is a simple matter of passing it to the model and asking for the probability that the predicted label is 1. A probability of 80% means the sentiment score is 0.8 and that the text is very positive."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Load and prepare the data\n\nThe first step is to load the dataset and prepare it for use in machine learning. Because machine-learning models can't deal with text, we'll use scikit-learn's [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) class to vectorize the training text. Then we'll split the data for training and testing."
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\n\ndf = pd.read_csv('Data/reviews.csv', encoding=\"ISO-8859-1\")\ndf.head()",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Once again Mr. Costner has dragged out a movie...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This is an example of why the majority of acti...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>First of all I hate those moronic rappers, who...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Not even the Beatles could write songs everyon...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Brass pictures (movies is not a fitting word f...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                                                Text  Sentiment\n0  Once again Mr. Costner has dragged out a movie...          0\n1  This is an example of why the majority of acti...          0\n2  First of all I hate those moronic rappers, who...          0\n3  Not even the Beatles could write songs everyon...          0\n4  Brass pictures (movies is not a fitting word f...          0"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Find out how many rows the dataset contains and confirm that there are no missing values."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.info()",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 50000 entries, 0 to 49999\nData columns (total 2 columns):\nText         50000 non-null object\nSentiment    50000 non-null int64\ndtypes: int64(1), object(1)\nmemory usage: 781.3+ KB\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Check for duplicate rows in the dataset."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.groupby('Sentiment').describe()",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"4\" halign=\"left\">Text</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>count</th>\n      <th>unique</th>\n      <th>top</th>\n      <th>freq</th>\n    </tr>\n    <tr>\n      <th>Sentiment</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>25000</td>\n      <td>24698</td>\n      <td>This show comes up with interesting locations ...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>25000</td>\n      <td>24884</td>\n      <td>Loved today's show!!! It was a variety and not...</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "            Text                                                            \\\n           count unique                                                top   \nSentiment                                                                    \n0          25000  24698  This show comes up with interesting locations ...   \n1          25000  24884  Loved today's show!!! It was a variety and not...   \n\n                \n          freq  \nSentiment       \n0            3  \n1            5  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The dataset contains a few hundred duplicate rows. Let's remove them and check for balance."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df = df.drop_duplicates()\ndf.groupby('Sentiment').describe()",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"4\" halign=\"left\">Text</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>count</th>\n      <th>unique</th>\n      <th>top</th>\n      <th>freq</th>\n    </tr>\n    <tr>\n      <th>Sentiment</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>24698</td>\n      <td>24698</td>\n      <td>A doctor who is trying to complete the medical...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>24884</td>\n      <td>24884</td>\n      <td>The reason I think this movie is fabulous is t...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "            Text                                                            \\\n           count unique                                                top   \nSentiment                                                                    \n0          24698  24698  A doctor who is trying to complete the medical...   \n1          24884  24884  The reason I think this movie is fabulous is t...   \n\n                \n          freq  \nSentiment       \n0            1  \n1            1  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Use [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to vectorize the text in the DataFrame's \"Text\" column using a built-in dictionary of stop words. Set `min_df` to 20 to ignore words that appear less than 20 times in the corpus of training text. This will reduce the likelihood of out-of-memory errors and will probably make the model more accurate as well."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.feature_extraction.text import CountVectorizer\n\nvectorizer = CountVectorizer(ngram_range=(1, 2), stop_words='english', min_df=20)\nx = vectorizer.fit_transform(df['Text'])\ny = df['Sentiment']",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "In addition to creating sparse matrices of vectorized text, `Countvectorizer` converts text to lowercase, removes stop words and punctuation characters, and more. Let's see how it cleans text before vectorizing it by transforming a string, and then reversing the transform."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "text = vectorizer.transform(['The long l3ines   and; pOOr customer# service really turned me off...123.'])\ntext = vectorizer.inverse_transform(text)\nprint(text)",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[array(['customer', 'long', 'poor', 'really', 'service', 'turned'],\n      dtype='<U25')]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Split the dataset for training and testing. We'll do a 50/50 split since the dataset contains nearly 50,000 samples."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5, random_state=0)  ",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Train a logistic-regression model\n\nThe next step is to train a classifier. We'll use scikit-learn's [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) classifier, which uses [logistic regression](https://en.wikipedia.org/wiki/Logistic_regression) to fit a model to the data."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression()\nmodel.fit(x_train, y_train)",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n",
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='warn',\n          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n          tol=0.0001, verbose=0, warm_start=False)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Validate the trained model with the 50% of the dataset aside for testing and show a confusion matrix."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import confusion_matrix\n\nconfusion_matrix(y_test, model.predict(x_test))",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "array([[10825,  1544],\n       [ 1419, 11003]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The model correctly identified 10,825 negative reviews as negative while misclassifying 1,419 of them. It correctly identified 11,003 positive reviews as positive and got it wrong 1,544 times. Use the `score` method to get a rough measure of the model's accuracy."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "model.score(x_test, y_test)",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "0.8804808196522932"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now retrieve the Receiver Operating Characteristic (ROC) metric for a better measure of accuracy."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import roc_auc_score\n\nprobabilities = model.predict_proba(x_test)\nroc_auc_score(y_test, probabilities[:, 1])",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "0.9462200082919553"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Use the model to analyze text\n\nLet's score a review by vectorizing the text of that review and passing it to the model's `predict_proba` method. Are the results consistent with what you would expect?"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "review = 'The long lines and poor customer service really turned me off.'\nmodel.predict_proba(vectorizer.transform([review]))[0][1]",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "0.17115375338199715"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now score a more positive review and see if the model agrees that the sentiment is positive."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "review = 'One of the more delightful experiences I have had!'\nmodel.predict_proba(vectorizer.transform([review]))[0][1]",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "0.6947404124772208"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Finish up by saving the model and its vocabulary."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pickle\n\npickle.dump(model, open('Data/sentiment_analysis.pkl', 'wb'))\npickle.dump(vectorizer.vocabulary_, open('Data/vocabulary.pkl', 'wb'))",
      "execution_count": 14,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}